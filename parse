import csv
import psycopg2
from psycopg2.extras import execute_batch
import os

CONN_PARAMS = {
    "host": "dl-gpdb-prod.fortebank.com",      # адрес хоста
    "port": 5432,                  # порт Greenplum
    "database": "gpdb",   # имя БД
    "user": "ngharifulla",             # пользователь
    "password": "n23062005G)"      # пароль
}
TABLE_NAME = "fgp_de_sandbox.test_kaspi_categories_all"
CSV_FILE = "kaspi_categories_child_root.csv"
COLUMNS = ["child", "root"]
TRUNC = True

def insert_csv_rows(
    csv_path: str,
    conn_params: dict,
    table: str,
    columns: list[str],
    batch_size: int = 1000,
    delimiter: str = "|",
    encoding: str = "utf-8",
):
    """
    Читает CSV без заголовка и вставляет данные в Greenplum пачками.
    
    :param csv_path: путь к CSV-файлу
    :param conn_params: параметры подключения к БД
    :param table: имя таблицы
    :param columns: список колонок, например ['bin','name']
    :param batch_size: размер пакета для execute_batch
    :param delimiter: разделитель в CSV
    :param encoding: кодировка файла
    """
    # Подключаемся
    conn = psycopg2.connect(**conn_params)
    cur  = conn.cursor()
    
    try:
        n = len(columns)
        placeholders = ", ".join(["%s"] * n)
        cols_sql     = ", ".join(columns)
        sql = f"INSERT INTO {table} ({cols_sql}) VALUES ({placeholders})"
        
        data = []
        with open(csv_path, "r", newline="", encoding=encoding) as f:
            reader = csv.reader(f, delimiter=delimiter)
            for row in reader:
                # если в строке меньше полей, пропускаем
                if len(row) < 2:
                    continue  
                # собираем первые n полей в кортеж
                batch.append((row[0], row[1]))
        
        if data:
            if TRUNC:
                cur.execute(f"TRUNCATE TABLE {table}")
            execute_batch(cur, sql, data, page_size=batch_size)
            conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        cur.close()
        conn.close()

def insert_csv_rows_executemany(
    csv_path: str,
    conn_params: dict,
    table: str,
    columns: list[str],
    batch_size: int = 1000,
    delimiter: str = "|",
    encoding: str = "utf-8",
    trunc: bool = False,
):
    """
    Читает CSV без заголовка и вставляет данные в Greenplum пакетами через cursor.executemany.

    :param csv_path: путь к CSV-файлу
    :param conn_params: параметры подключения к БД
    :param table: имя таблицы (schema.table)
    :param columns: список колонок, например ['bin','name']
    :param batch_size: размер пакета для executemany
    :param delimiter: разделитель в CSV
    :param encoding: кодировка файла
    :param trunc: выполнить TRUNCATE перед вставкой
    """

    n = len(columns)
    placeholders = ", ".join(["%s"] * n)
    cols_sql     = ", ".join(columns)
    sql = f"INSERT INTO {table} ({cols_sql}) VALUES ({placeholders})"

    conn = psycopg2.connect(**conn_params)
    cur  = conn.cursor()

    try:
        if trunc:
            cur.execute(f"TRUNCATE TABLE {table}")

        inserted = 0
        batch = []
        with open(csv_path, "r", encoding=encoding, newline="") as f:
            reader = csv.reader(f, delimiter=delimiter)
            for row in reader:
                if len(row) < 2:
                    continue
                batch.append((row[0], row[1]))

                if len(batch) >= batch_size:
                    cur.executemany(sql, batch)
                    inserted += len(batch)
                    print(f"Вставлено {inserted} строк...")
                    batch.clear()

        if batch:
            cur.executemany(sql, batch)
            inserted += len(batch)
            print(f"Вставлено {inserted} строк...")

        conn.commit()
        print(f"Завершено. Всего вставлено {inserted} строк.")

    except Exception:
        conn.rollback()
        raise
    finally:
        cur.close()
        conn.close()

if __name__ == "__main__":
    # insert_csv_rows(
    #     csv_path   = CSV_FILE,
    #     conn_params= CONN_PARAMS,
    #     table      = TABLE_NAME,
    #     columns    = COLUMNS  # передаёте столько, сколько нужно
    # )

    insert_csv_rows_executemany(
        csv_path = CSV_FILE,
        conn_params = CONN_PARAMS,
        table = TABLE_NAME,
        columns = COLUMNS,
        batch_size = 10000,
        delimiter = "|",
        encoding = "utf-8",
        trunc = TRUNC,
    )

    print("Готово: все строки вставлены.")


    
CREATE TABLE fgp_de_sandbox.kill_kaspi_merchants_detailed (
	merchant_id varchar(50) NULL,
	"name" varchar(100) NULL,
	phone varchar(20) NULL,
	create_date varchar(50) NULL,
	salescount numeric NULL,
	rating numeric NULL,
	ratingcount numeric NULL,
	reviewscount numeric NULL,
	parse_date date NULL
)
DISTRIBUTED BY (merchant_id);


CREATE TABLE fgp_de_sandbox.kill_kaspi_merchants (
	id varchar(100) NULL,
	merchant_id varchar(50) NULL,
	title varchar(100) NULL,
	"name" varchar(100) NULL,
	count numeric NULL,
	popularity numeric NULL,
	category varchar(50) NULL,
	parse_date date NULL,
	count_articuls varchar(100) NULL,
	count_brand varchar(100) NULL,
	sales_per_day numeric NULL,
	min_price numeric NULL,
	max_price numeric NULL,
	is_new_data bool DEFAULT false NOT NULL
)
DISTRIBUTED BY (id);

"id","merchant_id","title","name","count","popularity","category","parse_date","count_articuls","count_brand","sales_per_day","min_price","max_price","is_new_data"
"30291103_desktops","30291103",ИП TECH ORDA ELECTRONIC,ИП TECH ORDA ELECTRONIC,3,0,desktops,2025-08-11,,,,,,false
"30359584_bedroom mattresses","30359584",ECO MATRAS,ECO MATRAS,31,0,bedroom mattresses,2025-08-11,,,,,,false
"15013183_desktops","15013183",UA Store,UA Store,1,0,desktops,2025-08-11,,,,,,false
"30296028_bedroom mattresses","30296028",ТОО YOURHOUSE,ТОО YOURHOUSE,31,1,bedroom mattresses,2025-08-11,,,,,,false
"30336222_steam generators","30336222",ИП МАРИЯМ,ИП МАРИЯМ,4,0,steam generators,2025-02-06,,,,,,false
"30071150_foundation primers","30071150",Arzan.shop,Arzan.shop,1,1,foundation primers,2025-02-05,,,,,,false
"30330712_stoves and grills","30330712",ИП SHOPPING,ИП SHOPPING,16,5,stoves and grills,2025-02-13,,,,,,false
"30136823_kitchen gloves","30136823",ASM CHEMIA GROUP,ASM CHEMIA GROUP,6,2,kitchen gloves,2025-02-07,,,,,,false



